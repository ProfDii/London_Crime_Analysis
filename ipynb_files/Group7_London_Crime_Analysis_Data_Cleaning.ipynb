{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gbM8KCcECHNf"
   },
   "source": [
    "<center>\n",
    " # Introduction to Python Programming\n",
    "## Final Project\n",
    "### Submitted to: Flavio Pinheiro and Jorge Antunes\n",
    "\n",
    "------------------------------------------------------------------------------------------------------\n",
    "\n",
    "| First Name | Last Name | Student Number | E-mail Address\n",
    "| ------------------ | ----------------- | --------------------------- |-------------------------\n",
    "| Adeoluwa | Akande | D20170353 | D20170353@novaims.unl.pt\n",
    "| Carolina | Araujo | M20180262 | m20180262@novaims.unl.pt\n",
    "| Francisco | Freitas | M20170062 | m20170062@novaims.unl.pt\n",
    "| Julian | Kuypers | M20180409 | m20180409@novaims.unl.pt\n",
    "    \n",
    "------------------------------------------------------------------------------------------------------\n",
    "\n",
    "  </center>\n",
    "<div style=\"text-align: center\"> **Test** </div>\n",
    "  \n",
    "\n",
    "**Abstract**\n",
    "\n",
    "Incidents could either be crimes or other emergency situations that require immediate attention and help. The availability of the crime database of London provides us with a unique opportunity to track crime incidents and explore crime patterns. This in turn will help the authorities to optimize resource allocation and improve emergency call response. \n",
    "\n",
    "The aim of our research will be to:\n",
    "- Identify incidents patterns and hotspots\n",
    "- Predict future occurrence of crime \n",
    "- Generate visualizations to help the police and emergency response "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BOozfQRoCPLP"
   },
   "source": [
    "## Dataset Description\n",
    "\n",
    "To carry out this project, we made use of a dataset from the London data portal. The data contains reported cases of criminal activity from the London Police Department (SFPD). The data covers 01/08/2015 - 01/01/2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All datasets resulting from extracting, merging, and cleaning are available in a folder submitted by the students. There is no need to reset the paths and run the code again to create the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYk5EWA_CXAY"
   },
   "source": [
    "## Libraries installations and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LqjUDqYil5Zr"
   },
   "outputs": [],
   "source": [
    "# Loading relevant libraries\n",
    "import pydot\n",
    "import calendar\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ULMqXg-FbEUt"
   },
   "source": [
    "## Dataset Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jwu0_kBRYxhC"
   },
   "source": [
    "**Loading & Concatenating London Crime Data from City Police and Metropolitan Police**\n",
    "\n",
    "Because our study area is made up of the city of London and the greater London metropolitan area,  we essentially have crime data for these two areas.  The crime data for each of these areas comes in monthly chunks. Hence, each month is loaded, read individually and merged into a singlee file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "41Lnn9a6mgJ3"
   },
   "source": [
    "### ***Greater London Metropolitan Area Crime Data*** - Data comes in monthly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-V_FxFukOok"
   },
   "outputs": [],
   "source": [
    "#loading and grouping crime data of the greater London metropolitan area for 2018\n",
    "gr1801 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2018-01/2018-01-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1802 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2018-02/2018-02-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1803 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2018-03/2018-03-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1804 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2018-04/2018-04-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1805 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2018-05/2018-05-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1806 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2018-06/2018-06-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1807 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2018-07/2018-07-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1808 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2018-08/2018-08-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "\n",
    "gr2018 = [gr1801,gr1802,gr1803,gr1804,gr1805,gr1806,gr1807,gr1808]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rN0emhcPkOsM"
   },
   "outputs": [],
   "source": [
    "#loading and grouping crime data of the greater London metropolitan area for 2017\n",
    "gr1701 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2017-01/2017-01-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1702 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2017-02/2017-02-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1703 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2017-03/2017-03-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1704 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2017-04/2017-04-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1705 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2017-05/2017-05-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1706 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2017-06/2017-06-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1707 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2017-07/2017-07-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1708 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2017-08/2017-08-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1710 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2017-09/2017-09-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1711 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2017-10/2017-10-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1712 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2017-11/2017-11-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1709 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2017-12/2017-12-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "\n",
    "gr2017 = [gr1701,gr1702,gr1703,gr1704,gr1705,gr1706,gr1707,gr1708,gr1709,gr1710,gr1711,gr1712]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aligpGOukOvM"
   },
   "outputs": [],
   "source": [
    "#loading and grouping crime data of the greater London metropolitan area for 2015-2016\n",
    "gr1601 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2016-01/2016-01-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1602 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2016-02/2016-02-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1603 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2016-03/2016-03-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1604 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2016-04/2016-04-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1605 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2016-05/2016-05-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1606 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2016-06/2016-06-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1607 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2016-07/2016-07-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1608 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2016-08/2016-08-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1609 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2016-09/2016-09-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1610 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2016-10/2016-10-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1611 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2016-11/2016-11-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "gr1612 = pd.read_csv('/Users/jkuypers/Group7_IP_Cleaning:Merging/NewLondonCrime/2016-12/2016-12-metropolitan-street.csv', encoding='ISO-8859-1')\n",
    "\n",
    "gr20152016 = [gr1601,gr1602,gr1603,gr1604,gr1605,gr1606,gr1607,gr1608,\n",
    "             gr1609,gr1610,gr1611,gr1612]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VH2vHzKxnHt9"
   },
   "source": [
    "### ***London City Crime Data*** - Data comes in monthly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing City of London Street Crime Data\n",
    "import glob\n",
    "path =r'/Users/jkuypers/Group7_IP_Cleaning:Merging/LondonCrimeData2016-2018/'#UseYourPath\n",
    "allFiles = glob.glob(path + \"/20**-**-city-of-london-street.csv\")\n",
    "\n",
    "list_ = []\n",
    "\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None)\n",
    "    list_.append(df)\n",
    "\n",
    "    \n",
    "#df with all crimes in city London\n",
    "CityStreet = pd.concat(list_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oUCDjUPU06F_"
   },
   "source": [
    "## Data Wrangling & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g44_JVAx1odm"
   },
   "source": [
    "### ***Joining Greater London Metropolitan Area Crime Data with London City Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QIOxg_L61rrx"
   },
   "outputs": [],
   "source": [
    "#Concatenating monthly data into years for metropolitan police\n",
    "Greater2018= pd.concat(gr2018)\n",
    "Greater2017=pd.concat(gr2017)\n",
    "Greater20152016=pd.concat(gr20152016)\n",
    "\n",
    "#grouping all metropolitan data\n",
    "Metro = [Greater2018,Greater2017,Greater20152016]\n",
    "\n",
    "#turning metropolitan data into a df\n",
    "Metro = pd.concat(Metro)\n",
    "\n",
    "#grouping metropolitan and city data\n",
    "All = [CityStreet,Metro]\n",
    "\n",
    "#saving all data to one df\n",
    "GreaterLondon=pd.concat(All)\n",
    "\n",
    "\n",
    "#drop rows with no location data\n",
    "GreaterLondon = GreaterLondon.dropna(subset=['Longitude', 'Latitude','LSOA code'])\n",
    "\n",
    "#Saving to CSV\n",
    "\n",
    "# GreaterLondon.to_csv(r'Group7_Full_Crime_Dataset_GreaterLondon.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_VHxz7cK22wm"
   },
   "source": [
    "### ***London Housing Data - Only Using Mean Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading raw housing data\n",
    "housingMean = pd.read_excel('/Users/jkuypers/Group7_IP_Cleaning:Merging/AvgHousingPricesLondon.xls',sheet_name='Mean',skiprows=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUoynBK9o0xD"
   },
   "outputs": [],
   "source": [
    "#removing unnecessary columns (1995-2015)\n",
    "housingMean.drop(housingMean.iloc[:, 2:77], inplace=True, axis=1)\n",
    "\n",
    "#renaming columns of Average Housing Prices London\n",
    "\n",
    "housingMean = housingMean.rename(index=str,columns={\"Year ending Sep 2014\":\"Sep 2014\",\n",
    "                                                    \"Year ending Dec 2014\":\"Dec 2014\",\n",
    "                                                    \"Year ending Mar 2015\":\"Mar 2015\",\n",
    "                                                    \"Year ending Jun 2015\":\"Jun 2015\", \n",
    "                                                    \"Year ending Sep 2015\":\"Sep 2015\",\n",
    "                                                    \"Year ending Dec 2015\":\"Dec 2015\",\n",
    "                                                    \"Year ending Mar 2016\":\"Mar 2016\",\n",
    "                                                    \"Year ending Jun 2016\":\"Jun 2016\",\n",
    "                                                    \"Year ending Sep 2016\":\"Sep 2016\",\n",
    "                                                    \"Year ending Dec 2016\":\"Dec 2016\",\n",
    "                                                    \"Year ending Mar 2017\":\"Mar 2017\",\n",
    "                                                    \"Year ending Jun 2017\":\"Jun 2017\",\n",
    "                                                    \"Year ending Sep 2017\":\"Sep 2017\",\n",
    "                                                    \"Year ending Dec 2017\":\"Dec 2017\"})\n",
    "\n",
    "#dropping rows for borough outside of London\n",
    "housingMean = housingMean.drop(housingMean.index[33:])\n",
    "\n",
    "#converting average housing prices to integer\n",
    "for col in ['Sep 2014','Dec 2014','Mar 2015','Jun 2015','Sep 2015','Dec 2015','Mar 2016',\n",
    "            'Jun 2016','Sep 2016','Dec 2016','Mar 2017','Jun 2017','Sep 2017','Dec 2017']:\n",
    "  housingMean[col] = housingMean[col].astype(int)\n",
    "  \n",
    "#our dataset only shows the average housing price every three months - we want to have an average price for every month so we can match it\n",
    "#with our crime data.\n",
    "#We will create columns for the missing months and use the prices we know to estimate the average housing price during that month\n",
    "\n",
    "\n",
    "#Adding columns for each month with difference between known months divided by two (because two months\n",
    "# between each known month) - this way it increments/decreases accordingly\n",
    "#will use these columns to match with crime data\n",
    "housingMean['Oct 2014'] = housingMean['Sep 2014'] + ((housingMean['Dec 2014']-housingMean['Sep 2014'])/2)\n",
    "housingMean['Nov 2014'] = housingMean['Oct 2014'] + ((housingMean['Dec 2014']-housingMean['Sep 2014'])/2)\n",
    "housingMean['Jan 2015'] = housingMean['Dec 2014'] + ((housingMean['Mar 2015']-housingMean['Dec 2014'])/2)\n",
    "housingMean['Feb 2015'] = housingMean['Jan 2015'] + ((housingMean['Mar 2015']-housingMean['Dec 2014'])/2)\n",
    "housingMean['Apr 2015'] = housingMean['Mar 2015'] + ((housingMean['Jun 2015']-housingMean['Mar 2015'])/2)\n",
    "housingMean['May 2015'] = housingMean['Apr 2015'] + ((housingMean['Jun 2015']-housingMean['Mar 2015'])/2)\n",
    "housingMean['Jul 2015'] = housingMean['Jun 2015'] + ((housingMean['Sep 2015']-housingMean['Jun 2015'])/2)\n",
    "housingMean['Aug 2015'] = housingMean['Jul 2015'] + ((housingMean['Sep 2015']-housingMean['Jun 2015'])/2)\n",
    "\n",
    "housingMean['Oct 2015'] = housingMean['Sep 2015'] + ((housingMean['Dec 2015']-housingMean['Sep 2015'])/2)\n",
    "housingMean['Nov 2015'] = housingMean['Oct 2015'] + ((housingMean['Dec 2015']-housingMean['Sep 2015'])/2)\n",
    "housingMean['Jan 2016'] = housingMean['Dec 2015'] + ((housingMean['Mar 2016']-housingMean['Dec 2015'])/2)\n",
    "housingMean['Feb 2016'] = housingMean['Jan 2016'] + ((housingMean['Mar 2016']-housingMean['Dec 2015'])/2)\n",
    "housingMean['Apr 2016'] = housingMean['Mar 2016'] + ((housingMean['Jun 2016']-housingMean['Mar 2016'])/2)\n",
    "housingMean['May 2016'] = housingMean['Apr 2016'] + ((housingMean['Jun 2016']-housingMean['Mar 2016'])/2)\n",
    "housingMean['Jul 2016'] = housingMean['Jun 2016'] + ((housingMean['Sep 2016']-housingMean['Jun 2016'])/2)\n",
    "housingMean['Aug 2016'] = housingMean['Jul 2016'] + ((housingMean['Sep 2016']-housingMean['Jun 2016'])/2)\n",
    "\n",
    "housingMean['Oct 2016'] = housingMean['Sep 2016'] + ((housingMean['Dec 2016']-housingMean['Sep 2016'])/2)\n",
    "housingMean['Nov 2016'] = housingMean['Oct 2016'] + ((housingMean['Dec 2016']-housingMean['Sep 2016'])/2)\n",
    "housingMean['Jan 2017'] = housingMean['Dec 2016'] + ((housingMean['Mar 2017']-housingMean['Dec 2016'])/2)\n",
    "housingMean['Feb 2017'] = housingMean['Jan 2017'] + ((housingMean['Mar 2017']-housingMean['Dec 2016'])/2)\n",
    "housingMean['Apr 2017'] = housingMean['Mar 2017'] + ((housingMean['Jun 2017']-housingMean['Mar 2017'])/2)\n",
    "housingMean['May 2017'] = housingMean['Apr 2017'] + ((housingMean['Jun 2017']-housingMean['Mar 2017'])/2)\n",
    "housingMean['Jul 2017'] = housingMean['Jun 2017'] + ((housingMean['Sep 2017']-housingMean['Jun 2017'])/2)\n",
    "housingMean['Aug 2017'] = housingMean['Jul 2017'] + ((housingMean['Sep 2017']-housingMean['Jun 2017'])/2)\n",
    "housingMean['Oct 2017'] = housingMean['Sep 2017'] + ((housingMean['Dec 2017']-housingMean['Sep 2017'])/2)\n",
    "housingMean['Nov 2017'] = housingMean['Oct 2017'] + ((housingMean['Dec 2017']-housingMean['Sep 2017'])/2)\n",
    "\n",
    "#Using the pandas melt function to create a more maleable dataframe - this will be useful when merging with the crime dataset\n",
    "housingMean = housingMean.melt(id_vars = ['Code','Area'], value_vars=['Sep 2014', 'Dec 2014', 'Mar 2015', 'Jun 2015', 'Sep 2015',\n",
    "       'Dec 2015', 'Mar 2016', 'Jun 2016', 'Sep 2016', 'Dec 2016', 'Mar 2017',\n",
    "       'Jun 2017', 'Sep 2017', 'Dec 2017', 'Oct 2014', 'Nov 2014', 'Jan 2015',\n",
    "       'Feb 2015', 'Apr 2015', 'May 2015', 'Jul 2015', 'Aug 2015', 'Oct 2015',\n",
    "       'Nov 2015', 'Jan 2016', 'Feb 2016', 'Apr 2016', 'May 2016', 'Jul 2016',\n",
    "       'Aug 2016', 'Oct 2016', 'Nov 2016', 'Jan 2017', 'Feb 2017', 'Apr 2017',\n",
    "       'May 2017', 'Jul 2017', 'Aug 2017', 'Oct 2017', 'Nov 2017'], var_name='Month',value_name='Average Price')\n",
    "\n",
    "#converting Month to datetime + creating Year column as copy on month and later changing it to year - otherwise get 1970\n",
    "housingMean['Month'] = pd.to_datetime(housingMean['Month'])\n",
    "housingMean['Year'] = pd.to_datetime(housingMean['Month'])\n",
    "housingMean['Month'], housingMean['Year'] = housingMean['Month'].dt.month, housingMean['Year'].dt.year\n",
    "\n",
    "housingMean = housingMean.rename(index=str, columns={'Area':'Borough'})\n",
    "\n",
    "#exporting to csv - this cleaned data will be used for plotting and modeling\n",
    "\n",
    "# housingMean.to_csv('Group7_LondonHousingMeanPrice.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JU2P3vws5pKE"
   },
   "source": [
    "### ***Data Merging***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGKxn6716E6s"
   },
   "outputs": [],
   "source": [
    "# making list of Metropolitan police (Greater London) and London City Police (City of London)\n",
    "\n",
    "#concactenate into dataframe called LondonStreet - has all data from Metropolital and City Police\n",
    "LondonStreet = GreaterLondon\n",
    "\n",
    "#changing column names\n",
    "LondonStreet = LondonStreet.rename(index=str,columns={\"Unnamed: 0\":\"Crime_index\",\n",
    "                                                      \"Crime ID\":\"Crime_ID\",\n",
    "                                                      \"Reported by\":\"Reported_by\",\n",
    "                                                      \"Falls within\":\"Falls_within\",\n",
    "                                                      \"LSOA code\":\"LSOA_code\",\n",
    "                                                      \"LSOA name\":\"LSOA_name\",\n",
    "                                                      \"Crime type\":\"Crime_type\",\n",
    "                                                      \"Last outcome category\":\"Last_outcome_cat\"})\n",
    "\n",
    "#drop 'Context' in street - only contains NaN\n",
    "LondonStreet = LondonStreet.drop(columns=['Context'])\n",
    "\n",
    "\n",
    "LondonStreet['Month'] = pd.to_datetime(LondonStreet['Month'])\n",
    "LondonStreet['Year'] = pd.to_datetime(LondonStreet['Month'], format='%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQsqqlMUo0xT"
   },
   "outputs": [],
   "source": [
    "\n",
    "#create new column Borough - will use to merge with housing prices\n",
    "LondonStreet['Borough'] = LondonStreet['LSOA_name'].str.slice(0,-5)\n",
    "\n",
    "#create new df by merging crime and average housing price \n",
    "StreetCrimePrice = pd.merge(LondonStreet, housingMean, on=['Month','Year','Borough'])\n",
    "\n",
    "#dont need anymore since have it in borough column\n",
    "StreetCrimePrice = StreetCrimePrice.drop(columns=['LSOA_name'])\n",
    "\n",
    "\n",
    "#The 'Location' column has a few recurring locations such as parks, nighclubs, petrol stations\n",
    "# these location types could be useful in our analysis (types of locations where crimes occur) - All location descriptions\n",
    "# outside of 'commonLocations have been replaced with 'street', meaning the crime didn't happen in any of \n",
    "#these special location descriptions\n",
    "StreetCrimePrice['Location'] = StreetCrimePrice['Location'].str.slice(11,)\n",
    "\n",
    "CommonLocations = ['Nightclub','Police Station','Petrol Station','Parking Area','Park/Open Space']\n",
    "StreetCrimePrice.loc[~StreetCrimePrice[\"Location\"].isin(CommonLocations), \"Location\"] = \"Street\"\n",
    "\n",
    "\n",
    "#this model will be used for our analysis ()\n",
    "AnalysisModel = StreetCrimePrice.filter(items=['Longitude','Latitude','Location','Month','Year','Reported_by','Crime_type','Borough','Average Price',\n",
    "                                               'Last_outcome_cat'])\n",
    "\n",
    "AnalysisModel['Year'] = AnalysisModel['Year'].dt.year\n",
    "AnalysisModel['Month'] = AnalysisModel['Month'].dt.month\n",
    "\n",
    "#create a smaller sample file for professor to run analysis code\n",
    "SampleAnalysisModel = AnalysisModel.sample(frac=0.04)\n",
    "SampleAnalysisModel = SampleAnalysisModel.reset_index()\n",
    "\n",
    "#exporting to csv - this cleaned data will be used for plotting and modeling\n",
    "\n",
    "# AnalysisModel.to_csv('Group7_AnalysisModel.csv')\n",
    "# SampleAnalysisModel.to_csv('Group7_SampleAnalysisModel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keeping the five most occuring crimes - will be used for our models\n",
    "importantCrimes = ['Anti-social behaviour','Violence and sexual offences', 'Vehicle crime', 'Burglary','Criminal damage and arson']\n",
    "\n",
    "AlgoModel = AnalysisModel.loc[AnalysisModel['Crime_type'].isin(importantCrimes)]\n",
    "SampleAlgoModel = AlgoModel.sample(frac=0.04)\n",
    "SampleAlgoModel = SampleAlgoModel.reset_index()\n",
    "\n",
    "\n",
    "#Exporting to csv - this file will be used to run the scikit lean models\n",
    "\n",
    "# AlgoModel.to_csv('Group7_AlgoModel.csv')\n",
    "# SampleAlgoModel.to_csv('Group7_SampleAlgoModel.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Updated_Merged_London_Crime_&_Housing_Analysis.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
